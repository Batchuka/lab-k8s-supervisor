# Passo a passo para pr√°tica de provisionar k8s com CAPI na AWS

**OBJETIVO**: instanciar uma m√°quina EC2 na AWS e executar nela um cluster Kubernetes via kind, utilizado como management cluster para trabalhar com CRDs do Cluster API (CAPI).

**FERRAMENTAS** : Para isso usaremos `terraform` para provisionar e configurar recursos rapidamente, `ssh-keygen` para gerar chaves *ssh*, `AWS CLI` para dar comandos √† AWS e `OpenSSH` como cliente *ssh* para se conectar ao EC2.

## 1 ‚Äì Cria√ß√£o da chave SSH local

O `terraform` √© um utilit√°rio de linha de comando usado para configurar e provisionar recursos de forma declarativa. Entretanto, essa CLI n√£o oferece suporte a download. Ou seja, √© poss√≠vel us√°-lo para criar uma chave de acesso SSH para uma inst√¢ncia EC2, mas a ferramenta n√£o a baixa automaticamente, o que torna o processo in√∫til nesse contexto.

Ent√£o, vamos gerar o par de chaves localmente e export√°-lo para uso no EC2. Usando o utilit√°rio `ssh-keygen`, normalmente dispon√≠vel em sistemas Unix, geraremos as chaves que ser√£o usadas para acesso SSH √† inst√¢ncia EC2. Por favor, **navegue at√© a raiz do projeto** e d√™ o seguinte comando ‚Äî obs.: n√£o utilize nenhuma `passphrase`:

```bash
ssh-keygen -t ed25519 -f .aws/ec2-keys/k8s-bootstrap-lab-key.pem
```
Isso cria dois arquivos:
- aws/ec2-keys/k8s-bootstrap-lab-key.pem        ‚Üí chave privada (fica somente na m√°quina local)
- aws/ec2-keys/k8s-bootstrap-lab-key.pem.pub    ‚Üí chave p√∫blica (enviada √† AWS para compor o Key Pair)

N√£o coloque nenhuma frase nem nada, s√≥ d√™ enter 'vazio' em tudo.

## 2 ‚Äì Provisionar a inst√¢ncia EC2 com Terraform

Agora navegue at√© a pasta *k8s-lab-1-aws/terraform*. Nessa pasta, preciso que fa√ßa a [Configura√ß√£o das credenciais AWS](../.aws/README.md#configura√ß√£o-das-credenciais-aws).

Inicializar o Terraform:
```bash
terraform init
```

Ver o plano:
```bash
terraform plan
```

Aplicar:
```bash
terraform apply
```

√â importante, ap√≥s as pr√°ticas, remover toda a infraestrutura criada para evitar custos desnecess√°rios. Isso pode ser feito com o comando abaixo. Aten√ß√£o: ele remove **todos** os recursos gerenciados pelo Terraform no diret√≥rio atual. Tudo o que foi criado a partir da se√ß√£o 3 ser√° apagado.

```bash
terraform destroy
```


## 3 ‚Äî Acessar e Configurar a inst√¢ncia EC2

Para acessar a inst√¢ncia criada, voc√™ pode ir at√© `EC2 > Instances > **id_sua_instancia** > Connect to instance`. Ver√° um Exemplo de comando de conex√£o ssh, algo assim: `ssh -i "k8s-bootstrap-lab-key.pem" ubuntu@ec2-34-201-148-231.compute-1.amazonaws.com`. 

<p align="center"><img src="../docs/images/image1.png" width="500"><br><em>Onde encontrar o SSH de conex√£o no EC2</em></p>

> üîé **NOTA** : a parte *ubuntu@ec2-34-201-148-231.compute-1.amazonaws.com* √© din√¢mica e atribu√≠da pela AWS, pois est√° vinculada ao IP p√∫blico da inst√¢ncia. Ela muda quando a inst√¢ncia √© **parada** e **iniciada** novamente (ou **recriada**).

Eu irei criar uma vari√°vel essa parte din√¢mica, porque assim fica mais f√°cil para eu trabalhar.

```bash
export EC2_HOST=ubuntu@ec2-34-201-148-231.compute-1.amazonaws.com
ssh -i .aws/ec2-keys/k8s-bootstrap-lab-key.pem $EC2_HOST
```

Da√≠, fa√ßa as coisas coisas triviais:

> üîé **NOTA** : como op√ß√£o, eu implementei um script de configura√ß√£o da inst√¢ncia e voc√™ pode saber como usa-lo em [Configure sua M√°quina com um Script](bootstrap.md#configure-sua-m√°quina-com-um-script) ‚Äî mas recomendo que fa√ßa manualmente pelo menos uma vez para saber o que est√° rolando.

1. Atualizar o sistema e instalar algumas coisas:
```
sudo apt update && sudo apt upgrade -y
```

2. **Instalar Docker** (Kind precisa disso):
```bash
sudo apt install -y docker.io        # Instala o Docker a partir dos reposit√≥rios da distribui√ß√£o
sudo systemctl enable --now docker   # Habilita o servi√ßo do Docker e inicia imediatamente
sudo usermod -aG docker ubuntu       # Adiciona o usu√°rio 'ubuntu' ao grupo docker para executar comandos sem sudo
newgrp docker                        # Recarrega os grupos do usu√°rio e aplica o acesso ao Docker.
``` 

> üîé **NOTA** : Aqui √© bom entrar e sair de novo da conex√£o SSH, para for√ßar as permiss√µes. D√™ o comando `exit` e depois acesse a inst√¢ncia novamente.

3. **Instalar Kind**

O Kind √© `Kubernetes In Docker`, ele ser√° no nosso `Bootstrap Cluster` ‚Äî nome dado ao cluster que tem a capacidade de criar outros clusters, isto √©, ele serve para *fazer o bootstrap* de outros. A pr√°tica √© instalar uma vers√£o reduzida do *k8s*. O *Kind* serve a esse prop√≥sito.

```bash
# Baixa o bin√°rio do KIND (Kubernetes in Docker) para Linux
curl -Lo kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64

# Torna o arquivo baixado execut√°vel
chmod +x kind

# Move o bin√°rio para um diret√≥rio presente no PATH do sistema
# para que o comando 'kind' possa ser executado de qualquer lugar
sudo mv kind /usr/local/bin/

# Verifica se o KIND foi instalado corretamente e exibe a vers√£o
kind --version
```

4. **Instalar kubectl**

`kubectl` √© s√≥ o cliente que fala com o Kubernetes, √© um CLI.

```bash
# Baixa a vers√£o est√°vel mais recente do kubectl para Linux (amd64)
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

# Torna o bin√°rio do kubectl execut√°vel
chmod +x kubectl

# Move o kubectl para um diret√≥rio presente no PATH do sistema
# permitindo executar o comando de qualquer lugar
sudo mv kubectl /usr/local/bin/

# Verifica se o kubectl foi instalado corretamente
# e exibe a vers√£o do cliente
kubectl version --client
```

5. Criar o cluster Kind que ser√° o management cluster
```bash
# Cria um cluster Kubernetes local usando KIND
# O cluster ser√° executado dentro de containers Docker e receber√° o nome 'capi-mgmt'
kind create cluster --name capi-mgmt

# Lista os Nodes registrados no cluster rec√©m-criado
# permitindo verificar se o control plane est√° ativo
kubectl get nodes
```

## 4 ‚Äî Inicializa√ß√£o do Cluster API no cluster de gerenciamento (Kind)

Ta, agora eu vou explicar onde voc√™ est√° neste momento de uma forma mais ou menos visual:

```bash
Seu Desktop # Sua m√°quina local.
   .
   .
   .   (conex√£o SSH)
   .
   .
EC2 (t3.micro)
# Uma m√°quina virtual fornecida pela AWS.
# Para todos os efeitos, √© um computador remoto rodando Linux.
# Tudo o que vem abaixo depende dela estar ligada.

‚îî‚îÄ‚îÄ Docker
    # Um programa que roda continuamente nessa m√°quina (um daemon).
    # Ele permite executar aplica√ß√µes isoladas chamadas containers.
    # Esses containers compartilham o kernel da EC2, mas t√™m processos,
    # rede e filesystem isolados.

    ‚îî‚îÄ‚îÄ Container KIND
        # Um container criado pelo Docker.
        # Ele n√£o √© o Kubernetes em si.
        # Ele existe para CRIAR e HOSPEDAR um cluster Kubernetes usando containers.
        # Pense nele como um "ambiente controlado" onde o Kubernetes vai rodar.

        ‚îî‚îÄ‚îÄ Kubernetes
            # Agora sim, o sistema Kubernetes.
            # Ele √© composto por v√°rios processos que, juntos,
            # formam um cluster capaz de gerenciar aplica√ß√µes distribu√≠das.

            ‚îú‚îÄ‚îÄ control-plane
            # N√ÉO √© um node de execu√ß√£o.
            # √â o conjunto de componentes que controlam o cluster.
            # Ele:
            # - recebe comandos do usu√°rio (kubectl ‚Üí API Server)
            # - decide em qual node cada aplica√ß√£o deve rodar (Scheduler)
            # - garante que o estado desejado seja mantido (Controllers)
            # Sem o control-plane, o cluster n√£o toma decis√µes.

            ‚îú‚îÄ‚îÄ etcd
            # O banco de dados do Kubernetes.
            # Ele armazena o estado atual e desejado do cluster.
            # O control-plane consulta e atualiza o etcd o tempo todo.
            # Se o etcd √© perdido, o cluster perde sua mem√≥ria.

            ‚îî‚îÄ‚îÄ nodes (virtuais)
            # S√£o os locais onde as aplica√ß√µes realmente rodam.
            # Do ponto de vista do Kubernetes, s√£o m√°quinas.
            # Neste caso, s√£o apenas containers Docker simulando m√°quinas.
            # √â neles que os pods s√£o executados.

```

Em um desenho mais visual ficaria assim:

```mermaid
graph TD
    A[Seu Desktop] -.->|estabelece conex√£o SSH| B[EC2 t3.micro]

    B -->|possui um processo| C[Docker Daemon]
    C -->|est√° rodando um| D[Container KIND]
    D -->|√© uma imagem| E[Kubernetes Cluster]

    E -->|decide em| E1[Control Plane]
    E -->|persiste/consulta em| E2[etcd]
    E -->|delega workload| E3[Nodes Virtuais]
```


Agora, voc√™ vai adiconar mais uma camada de abstra√ß√£o de software em cima disso kkk ... √© o tal do **Cluster API** e assim teremos a seguinte estrutura:



```mermaid
graph TD
    A[Seu Desktop] -->|SSH| B[EC2 t3.micro]

    B --> C[Docker Runtime]
    C --> D[Container KIND]
    D --> E[Kubernetes Management Cluster]

    E --> E1[Control Plane]
    E --> E2[etcd]
    E --> E3[Nodes Virtuais]

    E --> F[Cluster API CAPI]
    F --> F1[CRDs Cluster Machine MachineSet]
    F --> F2[Controllers de Reconciliacao]
```


Para ter o CAPI, o caminho mais f√°cil √© instalar o `clusterctl`. Ele √© s√≥ um CLI que ir√° trocar uma ideia com o k8s dentro do container e pedir para instalar o CAPI.

```bash
# Baixa o bin√°rio do clusterctl (CLI do Cluster API) direto do GitHub
curl -L https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.7.2/clusterctl-linux-amd64 -o clusterctl

# Torna o arquivo execut√°vel
chmod +x clusterctl

# Move o bin√°rio para um diret√≥rio do PATH
# Assim o comando `clusterctl` pode ser executado de qualquer lugar
sudo mv clusterctl /usr/local/bin/
```

> üîé **NOTA** : `kubectl` √© o cliente gen√©rico do Kubernetes, operado em CLI. Fala com o API Server. Cria, l√™ e altera recursos Kubernetes. Inclui CRDs do CAPI, mas n√£o sabe inicializar nada. J√° o `clusterctl` √© o cliente espec√≠fico do Cluster API, operado em CLI. Ele instala os CRDs do CAPI, instala providers (que √© uma coisa que ainda n√£o discutimos) e valida vers√µes e compatibilidade. √â tipo um instalador, depois que usar ele pode voltar a usar kubectl.

> ‚≠ê **CONCEITO IMPORTANTE**:
Ao adicionar CRDs e controllers ao Kubernetes, voc√™ amplia o escopo do que ele consegue gerenciar. O Kubernetes deixa de orquestrar apenas aplica√ß√µes (pods, services, deployments) e passa a atuar como um plano de controle capaz de declarar, criar e manter recursos **de cloud** utilizados por essas aplica√ß√µes.

Mas antes, os controllers do Cluster API com provider AWS (CAPA) v√£o rodar dentro da EC2 e precisam criar recursos na AWS. Para isso, eles precisam de credenciais v√°lidas da AWS. Como voc√™ sabe, essas credenciais existem no seu desktop e n√£o existem no EC2. Logo, voc√™ precisa colocar l√°.

Ent√£o, volte na raiz do nosso projeto e d√™ os seguintes comandos:

```bash
# Acessa a EC2 via SSH
# Cria o diret√≥rio ~/.aws
# Esse √© o local padr√£o onde ferramentas e SDKs da AWS procuram credenciais
ssh -i .aws/ec2-keys/k8s-bootstrap-lab-key.pem ubuntu@ec2-< DIFERENTE >.compute-1.amazonaws.com "mkdir -p ~/.aws"

# Copia o arquivo credentials do seu desktop
# Envia para a EC2
# Coloca exatamente no caminho esperado pelas ferramentas da AWS
scp -i .aws/ec2-keys/k8s-bootstrap-lab-key.pem .aws/credentials ubuntu@ec2-< DIFERENTE >.compute-1.amazonaws.com:~/.aws/credentials
```

Agora sim, dentro da inst√¢ncia, fa√ßa isso:

```bash
# L√™ o arquivo de credenciais da AWS. Codifica em base64
# Exporta como vari√°vel de ambiente para o clusterctl usar
export AWS_B64ENCODED_CREDENTIALS=$(base64 -w0 ~/.aws/credentials)

# Inicializa o Cluster API no cluster Kubernetes atual
# Instala CRDs do CAPI
# Instala controllers
# Instala o provider de infraestrutura da AWS (CAPA)
clusterctl init --infrastructure aws

# Lista todos os pods em todos os namespaces
# Usado aqui para verificar se os controllers do CAPI/CAPA est√£o rodando
kubectl get pods -A

# Lista os CRDs instalados no cluster
# Filtra para mostrar os recursos relacionados ao Cluster API
kubectl get crds | grep cluster
```

Na pr√°tica, seu EC2 agora √© oficialmente um ‚Äúorquestrador de clusters Kubernetes e infraestrutura cloud‚Äù e nosso desenho mental ficou maior:


```mermaid
graph TD
    A[Seu Desktop] -->|SSH| B[EC2 t3.micro]

    B --> C[Docker Runtime]
    C --> D[Container KIND]
    D --> E[Kubernetes Management Cluster]

    E --> E1[Control Plane]
    E --> E2[etcd]
    E --> E3[Nodes Virtuais]

    E --> F[Cluster API CAPI]
    F --> F1[CRDs Cluster Machine MachineSet]
    F --> F2[Controllers de Reconciliacao]

    F --> G[Infrastructure Provider CAPA AWS]
    G --> G1[CRDs AWSCluster AWSMachine]
    G --> G2[Controllers AWS EC2 ELB]
```

## 5 - Pausa do caf√©: Uma conversa sobre a Infra que voc√™ criou.

Com isso, voc√™ instalou uma cama extra em cima do CAPI (*Cluster API*), voc√™ instalou o CAPA (*Cluster API Provider AWS*), que d√° ao CAPI o poder de criar recursos na AWS. Existem v√°rias 'entidades' nesse universo, v√°rios nomes que as vezes a gente n√£o entender bem o que s√£o. Aqui vai um desenho para te ajudar.

```mermaid
flowchart TD
    A[Kubernetes Core] --> B[Controller Pattern]
    A --> C[Custom Resource Definition - CRD]

    B --> D[Controller]
    C --> E[Custom Resource]

    D -->|reconcilia| E

    A --> F[API Server]
    F --> E

    subgraph Cluster API Project
        G[Cluster API - CAPI]
        G --> H[CRDs do CAPI<br/>Cluster, Machine, MachineSet]
        G --> I[Controllers do CAPI]
    end

    H -->|definem| E
    I -->|implementam| D

    subgraph Infrastructure Provider
        J[Provider AWS - CAPA]
        J --> K[CRDs AWS<br/>AWSCluster, AWSMachine]
        J --> L[Controllers AWS]
    end

    K --> E
    L --> D
```

Eu penso que agora precisamos discutir com muita clareza o **que voc√™ consegue fazer**, o poder que isso te deu.


## 6 ‚Äî Criar o Workload Cluster via CAPI

Definir vari√°veis do provider AWS
Essas vari√°veis s√£o consumidas pelo clusterctl e pelos controllers do CAPA.
```bash
export AWS_REGION="us-east-1"
export AWS_SSH_KEY_NAME="k8s-bootstrap-lab-key"
export AWS_CONTROL_PLANE_MACHINE_TYPE="t3.medium"
export AWS_NODE_MACHINE_TYPE="t3.medium"
```

Declarar o cluster (infraestrutura desejada)
Para o apply dos manifests dentro do cluster de gerenciamento.
Aqui voc√™ declara estado, n√£o cria recursos manualmente.
```bash
clusterctl generate cluster meu-cluster --kubernetes-version v1.28.5 | kubectl apply -f -
```

Acompanhar a reconcilia√ß√£o do cluster
Esses comandos mostram o CAPI materializando a infraestrutura na AWS.
Quer ver se ele j√° come√ßou? Roda:

```bash
kubectl get clusters
kubectl get awsclusters
kubectl get machines
kubectl get awsmachines
```

## 7 ‚Äî Acessar o Workload Cluster

## 8 ‚Äî Validar o Kubernetes do Workload Cluster

## 9 ‚Äî Provisionar Workload Can√¥nico