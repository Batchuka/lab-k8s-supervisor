# Fase 1 â€” Preparando o `control-plane` no EC2

## 1. RepositÃ³rio para organizaÃ§Ã£o

Construi um repositÃ³rio no github e deixei ele privado. Isso porque armazenarei as chaves '.pem' de conexÃ£o SSH nele.

ApÃ³s isso, clonei o repositÃ³rio em minha mÃ¡quina e criei um esquema de pastas bÃ¡sico: 'ec2/keys'.


## 2. CriaÃ§Ã£o da Instancia EC2

Fui atÃ© o console AWS â€” cujo acesso obtive pelo AWS Academy â€” e criei uma instancia EC2
    
    Resumo da sua instÃ¢ncia:
        â€¢ AMI: Ubuntu Server 22.04 LTS (x86_64)
        â€¢ Tipo: t2.medium (2 vCPUs, 4 GiB RAM)
        â€¢ Nome: capi-bootstrap-ec2
        â€¢ Acesso: via SSH com chave capi-bootstrap-key.pem
        â€¢ Uso: ServirÃ¡ como host para o Kind + Cluster API (bootstrap)

## 3. ConexÃ£o com Instancia EC2

ApÃ³s isso, no vscode, abri o terminal no diretÃ³rio onde estavam as chaves e dei os comandos de conexÃ£o com a instancia EC2. Uma conexÃ£o usando cliente 'ssh', funcionou no windows pois uso o 'git bash' que Ã© um terminal com os utilitÃ¡rios do Linux.

## 4. Instalando alguns utilitÃ¡rios

ApÃ³s acessar a mÃ¡quina, eu instalei alguns utilitÃ¡rios:

    â€¢ Docker: necessÃ¡rio para o Kind funcionar, pois ele cria containers Docker que simulam nodes Kubernetes.
    â€¢ curl: usado para baixar ferramentas como Kind, kubectl e clusterctl via terminal.
    â€¢ git: Ãºtil para clonar repositÃ³rios e versionar arquivos da prÃ¡tica, como YAMLs do CAPI.

## 5. ConfiguraÃ§Ã£o do Docker

ApÃ³s isso, dei comandos para configurar o docker. Em especial, configurei a inicializaÃ§Ã£o dele no boot â€” irei desligar a mÃ¡quina eventualmente para evitar gastos no AWS Academy, por isso, para facilitar minha vida, quero que o docker inicialize sempre no boot. Aqui sÃ£o os comandos:

```
sudo systemctl enable docker          # ativa no boot
sudo systemctl start docker           # inicia agora
sudo usermod -aG docker $USER         # libera uso sem sudo (requer logout/login)
``` 
    


## 6. InstalaÃ§Ã£o de Recursos importantes
    
ApÃ³s isso, instalei alguns recursos importantes:

    
`kind`
â€¢ Para que serve? Cria um mini-cluster Kubernetes local, rodando em containers Docker.
â€¢ Qual problema resolve? Te dÃ¡ um ambiente Kubernetes funcional sem precisar criar vÃ¡rias VMs ou configurar redes reais. Ideal pra testes e labs.
â€¢ Ã‰ o quÃª? Um utilitÃ¡rio de linha de comando que usa Docker por baixo.

`kubectl`
â€¢ Para que serve? Ã‰ o â€œcontrole remotoâ€ do Kubernetes â€” permite enviar comandos, ver pods, aplicar configs, etc.
â€¢ Qual problema resolve? Sem ele, vocÃª nÃ£o consegue interagir com o cluster. Ele Ã© a ponte entre vocÃª e o Kubernetes.
â€¢ Ã‰ o quÃª? Um cliente de linha de comando oficial do Kubernetes.

`clusterctl`
â€¢ Para que serve? Inicializa e gerencia o Cluster API â€” ferramenta que cria e mantÃ©m clusters Kubernetes automaticamente.
â€¢ Qual problema resolve? Criar clusters Kubernetes manualmente Ã© trabalhoso; o CAPI automatiza isso. E o clusterctl Ã© como vocÃª conversa com ele.
â€¢ Ã‰ o quÃª? Um CLI (utilitÃ¡rio) oficial do Cluster API.

VocÃª usa o Kind para criar rapidamente um cluster Kubernetes local, rodando via Docker â€” esse cluster Ã© o ambiente onde tudo comeÃ§a. Dentro dele, vocÃª usa o clusterctl para instalar o Cluster API, que Ã© um conjunto de controladores capazes de criar e gerenciar outros clusters Kubernetes. O clusterctl inicializa o CAPI, gera os arquivos de definiÃ§Ã£o do novo cluster e aplica tudo usando o cluster atual como base. JÃ¡ o kubectl entra como sua ferramenta de controle: Ã© com ele que vocÃª inspeciona, aplica ou modifica recursos nos clusters (incluindo o Kind e os gerenciados). Assim, os trÃªs se encadeiam: Kind cria o ambiente, clusterctl instala o CAPI, e kubectl interage com tudo.
    
```
# Instalar Kind 
curl -Lo kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64 
chmod +x kind && sudo mv kind /usr/local/bin/

# Instalar kubectl 
curl -LO https://dl.k8s.io/release/v1.30.1/bin/linux/amd64/kubectl 
chmod +x kubectl && sudo mv kubectl /usr/local/bin/

# Instalar clusterctl 
curl -L https://github.com/kubernetes-sigs/cluster-api/releases/latest/download/clusterctl-linux-amd64 -o clusterctl 
chmod +x clusterctl && sudo mv clusterctl /usr/local/bin/
``` 

## 7. Inicializar o Cluster

- kind = Kubernetes IN Docker: ele cria um cluster local dentro de containers Docker.
- VocÃª nÃ£o instalou um cluster full bare-metal ou com kubeadm.
- O que temos Ã© um ambiente leve e descartÃ¡vel, ideal como "bootstrap cluster" pro Cluster API.

EntÃ£o atÃ© agora, vocÃª:

- Instalou Docker.
- Instalou kubectl, kubelet, kubeadm.
- Criou um mini-cluster Kubernetes dentro da EC2 usando kind.

```
kind create cluster --name capi-bootstrap
```

A resposta esperada Ã© :

    Creating cluster "capi-bootstrap" ...
    âœ“ Ensuring node image (kindest/node:v1.27.3) ğŸ–¼ 
    âœ“ Preparing nodes ğŸ“¦  
    âœ“ Writing configuration ğŸ“œ 
    âœ“ Starting control-plane ğŸ•¹ï¸ 
    âœ“ Installing CNI ğŸ”Œ 
    âœ“ Installing StorageClass ğŸ’¾ 
    Set kubectl context to "kind-capi-bootstrap"      
    You can now use your cluster with:

    kubectl cluster-info --context kind-capi-bootstrap

    Thanks for using kind! ğŸ˜Š

**1.  Ensuring node image (kindest/node:v1.27.3)**
â†’ Baixa (ou reusa) a imagem Docker que simula um nÃ³ Kubernetes.

    Ã‰ literalmente um container que age como se fosse uma VM com K8s! Ele simula um nÃ³ K8 completo (control-plane), com todos os binÃ¡rios internos (kubelet, kubeadm, etcd, etc.)

**2. Preparing nodes**
â†’ Cria e inicializa os containers que representarÃ£o os nÃ³s do cluster. No caso, nenhum alÃ©m do `capi-bootstrap-control-plane` foi criado.

**3. Writing configuration**
â†’ Gera os arquivos de configuraÃ§Ã£o (kubeadm.yaml, etc) pra subir o cluster.

Exemplos:

- `/etc/kubernetes/manifests/kube-apiserver.yaml` â†’ define o pod estÃ¡tico do API server, coraÃ§Ã£o do cluster.

- `/etc/kubernetes/manifests/etcd.yaml` â†’ especifica o etcd, banco chave-valor que guarda o estado do cluster.

- `/etc/kubernetes/manifests/kube-controller-manager.yaml` â†’ orquestra controladores como deployments e replica sets.

- `/etc/kubernetes/manifests/kube-scheduler.yaml` â†’ decide em qual nÃ³ cada pod serÃ¡ executado.

- `/etc/kubernetes/pki/ca.crt` â†’ certificado da autoridade raiz, essencial para a autenticaÃ§Ã£o e seguranÃ§a das comunicaÃ§Ãµes.

**4. Starting control-plane**
â†’ Inicia o nÃ³ principal (control-plane) e cria:

- etcd : banco de dados chave-valor que guarda todo o estado do Kubernetes.
- kube-apiserver : expÃµe a API do cluster, recebe comandos kubectl e requisiÃ§Ãµes externas.
- kube-controller-manager : mantÃ©m a â€œvidaâ€ dos objetos (replicas, endpoints, etc.).
- kube-scheduler : decide em qual nÃ³ cada pod novo serÃ¡ executado.

**5. Installing CNI**
â†’ Instala o Container Network Interface, ou seja, o plugin de rede entre pods.
    
- Sobe kindnet (ou outro plugin de rede). Plugin CNI responsÃ¡vel pela comunicaÃ§Ã£o entre pods.

**6. Installing StorageClass**
â†’ Cria uma classe de armazenamento padrÃ£o para volumes dinÃ¢micos (PVCs).

- Isso permite que vocÃª use PersistentVolumeClaim nos seus pods. 

**7. Set kubectl context to "kind-capi-bootstrap"**
â†’ O kubectl jÃ¡ foi configurado para apontar pro cluster recÃ©m-criado.

- Agora vocÃª pode usar kubectl get nodes direto, sem mais configs.
- kube-proxy â†’ cria as regras de rede (iptables/ipvs) para expor serviÃ§os e balancear trÃ¡fego. 
- coredns â†’ serviÃ§o DNS interno, traduz nomes de serviÃ§o para IPs dentro do cluster.

## 8. InstalaÃ§Ã£o do Cluster API no bootstrap Cluster (Kind)

Com o comando abaixo, estaremos instalando os controladores do CAPI no 'namespace = capi-system'.

```
clusterctl init --infrastructure docker
```

EntÃ£o, no cluster Kind:

- Instalou o `cert-manager` (para gerenciar certificados).
- Instalou os providers: `cluster-api`, `bootstrap-kubeadm`, `control-plane-kubeadm` e `infrastructure-docker`.
- Cada um foi colocado no seu namespace (`capi-system`, `capi-kubeadm-bootstrap-system`, etc.).

NÃ£o sÃ£o contÃªineres â€œsoltosâ€ como no Docker, mas controllers do Kubernetes. Cada provider Ã© um controlador que observa objetos CRD (ex: Cluster, Machine) e executa as aÃ§Ãµes correspondentes (via API/SSH/infra) â€” ou seja, sÃ£o processos rodando dentro de um pod. Esse pod, por sua vez, roda dentro de um container Docker hospedado no contÃªiner-nÃ³ `capi-bootstrap-control-plane`. 

EntÃ£o a hierarquia Ã©:

0. MÃ¡quina EC2 â†’ roda Docker.
1. ContÃªiner Kind (capi-bootstrap-control-plane) â†’ simula um nÃ³ Kubernetes.
2. Kubernetes dentro do Kind â†’ sobe pods.
3. Pods â†’ cada provider Ã© um pod (logo, um container) que executa o software do CAPI

**Em essÃªncia:** eles sÃ£o binÃ¡rios Go compilados que implementam controladores, empacotados como imagens Docker, rodando como pods no cluster de bootstrap.

## 9. Gerar o manifesto de um cluster de destino

```
clusterctl generate cluster control-plane \
  --kubernetes-version v1.30.0 \
  --control-plane-machine-count=1 \
  --worker-machine-count=1 \
  | kubectl apply -f -
```


# SituaÃ§Ãµes comuns na prÃ¡tica

## O que Ã© o `kind`?

o `Kind` nÃ£o Ã© o `control-plane`, ele sÃ³ te dÃ¡ um cluster Kubernetes descartÃ¡vel (o bootstrap cluster). Dentro dele vocÃª instala os controladores do Cluster API (CAPI). Esses controladores, sim, vÃ£o orquestrar a criaÃ§Ã£o de um novo control-plane real (com etcd, kube-apiserver, etc.) nos nÃ³s que vocÃª indicar. 

EntÃ£o: Kind = bootstrap cluster; nele roda o CAPI; o CAPI cria e gerencia o control-plane e os workers â€œde verdadeâ€.


## O que Ã© o `clusterctl`?

O clusterctl Ã© um CLI oficial do Cluster API. Ele serve para inicializar o CAPI dentro de um cluster de bootstrap (ex: Kind), alÃ©m de gerar manifestos e gerenciar upgrades dos componentes do CAPI.


## O que acontece quando vocÃª reinicia a instancia EC2?

Ã‰ muito o EC2 trocar o IP interno da mÃ¡quina. Oque acontece? a instancia Ã© trocada? a infra Ã© outra? o EC2 drena? Zonas de disponibilidade.

ApÃ³s ter configurado a mÃ¡quina eu a reinicializei. Com os comandos abaixo constatei que estava tudo em pÃ©:

![Container 'Kind' no ar apÃ³s reiniciar](image/image1.png)
